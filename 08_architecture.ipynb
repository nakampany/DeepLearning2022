{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nakampany/DeepLearning2022/blob/main/08_architecture.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iuKgECqf4NLQ"
      },
      "source": [
        "# 簡単な画像分類モデルの実装\n",
        "## 概要\n",
        "- 深層学習ライブラリPytorchを用いることで，これまで学んだモデルを容易に構築することができる．\n",
        "- 画像分類問題を対象に，モデル構築の実践練習を行う．\n",
        "- データセットは0-9の手書き数字認識データセットのMNISTを用いる．\n",
        "\n",
        "## MNIST\n",
        "- 0-9の手書き数字認識データセット\n",
        "- 訓練用6万枚，検証用1万枚の画像＋ラベル（0-9）のペアで構成される．\n",
        "- 一枚の画像はグレースケール(1ch)の28x28のため，$\\boldsymbol{x} \\in R^{60000 \\times 1 \\times 28 \\times 28}$\n",
        "- http://yann.lecun.com/exdb/mnist/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "SpukZqg-4NLU"
      },
      "outputs": [],
      "source": [
        "# MNISTデータセットをロードする。\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "'''  # 大学内のProxy環境の場合，以下のコードを実行する必要があるかも．\n",
        "datasets.MNIST.resources = [\n",
        "    ('https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz', 'f68b3c2dcbeaaa9fbdd348bbdeb94873'),\n",
        "    ('https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz', 'd53e105ee54ea40749a09fcbcd1e9432'),\n",
        "    ('https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz', '9fb629c4189551a2d022fa330f9573f3'),\n",
        "    ('https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz', 'ec29112dd5afa0611ce80d1b7f02629c')\n",
        "]\n",
        "'''\n",
        "\n",
        "# データ拡張として標準化とTensor化を行う．\n",
        "transform = transforms.Compose([transforms.ToTensor(),\n",
        "                                 transforms.Normalize((0.5, ), (0.5, ))])\n",
        "ds_train = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "ds_test = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# DataLoader を作成する。\n",
        "batch_size = 128  # バッチサイズ\n",
        "#batch_size = 512  # メモリが小さい環境の場合，この値を小さくしてね．\n",
        "dl_train = torch.utils.data.DataLoader(ds_train, batch_size=batch_size, shuffle=True)\n",
        "dl_test  = torch.utils.data.DataLoader(ds_test,  batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdGM4ETF4NLV"
      },
      "outputs": [],
      "source": [
        "# データの中身を確認する．for文で中身を読み込む\n",
        "for x,y in dl_train:\n",
        "    break\n",
        "print(y.shape)\n",
        "#print(y)\n",
        "print(x.shape)\n",
        "#print(x[0])\n",
        "print(y[0])\n",
        "transforms.functional.to_pil_image(x[0].view(28, 28))  # 画像の確認"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLOt8ysf4NLW"
      },
      "source": [
        "# Pytorchを用いたNNの学習\n",
        "Pytorchを用いたNNの学習は以下の手順で実装できる．\n",
        "1. 【モデル設計】nn.Moduleを用いてネットワークを設計する．\n",
        "2. 【モデル準備】ネットワークをインスタンス化する．\n",
        "3. 【訓練の準備】損失関数をインスタンス化する．\n",
        "4. 【訓練の準備】最適化手法をインスタンス化する．\n",
        "5. 【訓練】以下の手順をイテレーションする．\n",
        "  1. 訓練データの一部$(x, y)$をサンプリングする．\n",
        "  2. ネットワークに$x$を入力し予測結果$p$を得る．\n",
        "  3. 損失関数を用いて$y$と$p$の誤差を算出する．\n",
        "  4. 誤差を逆伝播させ，最適化手法を用いてネットワークの重みを更新する．\n",
        "6. 【予測/評価】訓練済みモデルをテストデータで評価する．\n",
        "\n",
        "## 【モデル設計】nn.Moduleを用いてネットワークを設計\n",
        "- Pytorchでモデルを構築する際に一つのブロックをnn.Moduleのサブクラスとして定義して使用すると便利である．\n",
        "- nn.Moduleはコンストラクタでレイヤをインスタンス化し，forward()で順伝播を定義する．\n",
        "\n",
        "### nn.Moduleの定義\n",
        "- nn.Moduleを継承したサブクラスを定義する．\n",
        "- 基本的にはコンストラクタで必要な部品を調達し，forward()で処理を書く．\n",
        "- 今回はシンプルな4層のMulti-layer Perceptron（MLP）を実装する．\n",
        " - 入力（1x28x28次元）→Reshape（748次元）→全結合層（512次元）→全結合層（256次元）→全結合層（128次元）→出力層（10次元）"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BNZ6Lzas4NLX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# 非常にシンプルな4層のMLPを設計する．\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(SimpleNet, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        # nn.Sequential()に積層していく\n",
        "        self.main = nn.Sequential(\n",
        "            nn.Linear(input_dim, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(512, 256),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(256, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(128, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # (?, 1, 28, 28)で入力されるので(?, 784)に変形する28*28　メソッド\n",
        "        x = x.view(-1, self.input_dim)\n",
        "        # nn.Sequential()は層の塊（ブロック）として動作する\n",
        "        return self.main(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKBm5DTl4NLX"
      },
      "outputs": [],
      "source": [
        "# SimpleNetは(748→512→256→128→10)と変形させるネットワークである．\n",
        "# インスタンス化　実体化\n",
        "net = SimpleNet(28*28, 10)  # 入力(748)→出力(10)\n",
        "net"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fFhqskVM4NLX"
      },
      "source": [
        "## 【モデル準備】ネットワークをインスタンス化\n",
        "### nn.Moduleの利用\n",
        "- nn.ModuleのサブクラスSimpleNetをインスタンス化して利用してみる．"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_default_device() -> str:\n",
        "    if torch.cuda.is_available():\n",
        "        return \"cuda\"\n",
        "    elif getattr(torch.backends, \"mps\", None) is not None and torch.backends.mps.is_available():\n",
        "        return \"mps\"\n",
        "    else:\n",
        "        return \"cpu\"\n",
        "\n",
        "# GPUを使用する。\n",
        "#device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "device = get_default_device()"
      ],
      "metadata": {
        "id": "K9c8EhHWiZfT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P28LdG0k4NLY"
      },
      "outputs": [],
      "source": [
        "# SimpleNetは(748→512→256→128→10)と変形させるネットワークである．\n",
        "net = SimpleNet(28*28, 10)  # 入力(748)→出力(10)\n",
        "\n",
        "# 出力を試しに確認してみる．\n",
        "for x,y in dl_train: # 1イテレーション分のデータを取得\n",
        "    break\n",
        "out = net(x)\n",
        "print(\"Xの書式\", x.shape)\n",
        "print(\"Shapeの確認\", out.shape)\n",
        "print(\"1データ目の出力\", out[0])\n",
        "transforms.functional.to_pil_image(x[0].view(28, 28))  # 画像の確認"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nXgLkkkI4NLZ"
      },
      "source": [
        "- 上述のように，インスタンス化したnetは関数のように利用可能である．\n",
        "```python\n",
        "net = SimpleNet(28*28, 10)  # インスタンス化\n",
        "out = net(x)                # 関数のように利用可能\n",
        "```\n",
        "- したがって，入力$x \\in \\mathbb{R}^{128 \\times 1 \\times 28 \\times 28}$をnetに代入すると，\n",
        " - $\\mathbb{R}^{128 \\times 748}$の書式に変換される．\n",
        " - net.mainにより$\\mathbb{R}^{128 \\times 10}$の書式に変換される．\n",
        "- 予測結果[0]と入力画像[0]の例も示している．\n",
        " - ただしnetは未訓練のため乱数が10個出力されるだけである．\n",
        "\n",
        "## 【訓練の準備】損失関数と最適化手法をインスタンス化\n",
        "### 訓練の準備\n",
        "- Pytorchのモデルの訓練に必要な情報を事前準備する．\n",
        "- 必要なのは以下の2点\n",
        " - 損失関数：今回は一般的な分類問題で用いられるCategorical Cross-Entropy Loss\n",
        " - 最適化手法（optimizer）：今回は標準的なOptimizerとしてAdamを学習率0.001で"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "DJgwZJoC4NLZ"
      },
      "outputs": [],
      "source": [
        "# 損失関数：Pytorch標準のbinary cross entropy lossを採用する．\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 最適化手法：Adamをlr=0.001で利用する．\n",
        "lr = 0.001\n",
        "opt = torch.optim.Adam(net.parameters(), lr=lr) # netのパラメータを入れる．"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awZ_ztS94NLZ"
      },
      "source": [
        "## 【訓練】以下の手順をイテレーション\n",
        "1. 訓練データの一部$(x, y)$をサンプリングする．\n",
        "2. ネットワークに$x$を入力し予測結果$p$を得る．\n",
        "3. 損失関数を用いて$y$と$p$の誤差を算出する．\n",
        "4. 誤差を逆伝播させ，最適化手法を用いてネットワークの重みを更新する．\n",
        "\n",
        "今回は1イテレーション（1 epoch）を関数化して実装する．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "GReIbW3U4NLa"
      },
      "outputs": [],
      "source": [
        "# 1エポック実行\n",
        "def train(net, opt, criterion, loader, device=\"cpu\"):\n",
        "    net.train() #NETを訓練モードにする\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    # loader内のデータを1周訓練させる\n",
        "    for i, (inputs, labels) in enumerate(loader, 0):\n",
        "        opt.zero_grad()  # 勾配をゼロにする．\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        \n",
        "        out = net(inputs)   # Feed forward\n",
        "        loss = criterion(out, labels)  # Calculate Loss\n",
        "        loss.backward()     # Backward\n",
        "        opt.step()    # Update weights\n",
        "        \n",
        "        correct += sum(out.argmax(dim=1)==labels)\n",
        "        running_loss += loss.item()\n",
        "    train_acc = (correct/len(loader.dataset)).cpu().item()\n",
        "    return running_loss, train_acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0qAfWmK4NLa"
      },
      "source": [
        "## 【予測/評価】訓練済みモデルをテストデータで評価\n",
        "- 訓練中にテスト性能を評価したいので，評価関数を事前に作成しておく．\n",
        "- 訓練データとは別のデータセット（テストデータ）を用いて訓練済みモデルの性能を評価する．\n",
        "- 今回は評価を関数化して実装する．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylde2O0u4NLa"
      },
      "outputs": [],
      "source": [
        "# 評価\n",
        "def evaluate(net, loader, device=\"cpu\"):\n",
        "    net.eval()  # netを評価モードにする．\n",
        "\n",
        "    with torch.no_grad():  # 評価なので勾配計算を不要とする．\n",
        "        Xs, ys, preds = [], [], []\n",
        "        for inputs, labels in loader:\n",
        "            Xs.append(inputs)\n",
        "            ys.append(labels.detach().numpy())\n",
        "            preds.append(net(inputs.to(device)).to(\"cpu\").detach().numpy())\n",
        "\n",
        "    import numpy as np\n",
        "    Xs = torch.cat(Xs, dim=0)\n",
        "    ys = np.concatenate(ys, axis=0)\n",
        "    preds = np.concatenate(preds, axis=0).argmax(axis=1)\n",
        "    acc = (ys==preds).mean()\n",
        "    return acc, (Xs, ys, preds)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7JvR88kQ4NLb"
      },
      "source": [
        "### モデル全体の訓練\n",
        "- 訓練はデータを1周するだけではなく，繰り返し学習することで行われる．\n",
        "- 1周を1epochと呼ぶ．\n",
        "- net.train()はPytorchには訓練時と検証時でモデルの挙動を変更するためのメソッドがある．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GwqpCoJe4NLb"
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import trange\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "hist = []\n",
        "n_epochs = 20  # 20 epochs訓練する\n",
        "\n",
        "net = net.to(device)  # GPUで訓練できるようにする．\n",
        "net.train()  # netを訓練モードにする．\n",
        "\n",
        "for epoch in trange(n_epochs, desc=\"epoch\"):  # 訓練\n",
        "    loss, train_acc = train(net, opt, criterion, dl_train, device)\n",
        "    test_acc, _ = evaluate(net, dl_test, device)\n",
        "    hist.append([loss, train_acc, test_acc])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47I8ZJd14NLb"
      },
      "source": [
        "### 訓練結果の可視化\n",
        "- Categorical Cross-entropy Lossを最小化するよう訓練が進んでいる．\n",
        "- Epochごとの訓練の推移を可視化してみる．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60VpXTeW4NLb"
      },
      "outputs": [],
      "source": [
        "def plot_history(history):\n",
        "    fig, ax1 = plt.subplots()\n",
        "\n",
        "    # 損失の推移を描画する。\n",
        "    ax1.plot(history[:, 0], label=\"train loss\", linestyle=\"dashed\", marker = 'o')\n",
        "    ax1.set_xlabel(\"Epoch\")\n",
        "    \n",
        "    ax2 = ax1.twinx()\n",
        "    ax2.plot(history[:, 1], label=\"train acc\", marker = 'o')\n",
        "    ax2.plot(history[:, 2], label=\"test acc\", marker = 'o')\n",
        "\n",
        "    fig.legend(loc=\"center\")\n",
        "    plt.show()\n",
        "\n",
        "plot_history(np.array(hist))\n",
        "print(hist[-1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nH8nAnvd4NLc"
      },
      "source": [
        "- train lossとtrain accに着目すると，いずれも改善傾向が見られる（lossは減少，accは上昇）．\n",
        "- test acc二着目すると，同様に改善傾向はあるがtrain_accに追いつけない傾向がある．\n",
        "- もう少し訓練を進めること収束しそうである．\n",
        "\n",
        "### 画像と予測結果の可視化\n",
        "- せっかくなので画像と予測結果を可視化してみる．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cxiEQ1tk4NLc"
      },
      "outputs": [],
      "source": [
        "acc, (Xs, ys, preds) = evaluate(net.to(device), dl_test, device)\n",
        "\n",
        "a, b =300, 350\n",
        "\n",
        "# 画像を格子状に並べる。\n",
        "img = torchvision.utils.make_grid(torch.Tensor(Xs[a:b]), nrow=10, normalize=True, pad_value=1)\n",
        "# テンソルを PIL Image に変換する。\n",
        "img = transforms.functional.to_pil_image(img)\n",
        "\n",
        "print(ys[a:b].reshape(-1, 10))\n",
        "print(preds[a:b].reshape(-1, 10))\n",
        "print((ys[a:b]==preds[a:b]).reshape(-1,10))\n",
        "img"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kF9eL0Pi4NLc"
      },
      "source": [
        "## せっかくなので，CNNも試してみる．\n",
        "- シンプルな4層のCNNを構築してみよう．\n",
        "- カーネルサイズは大きめに5x5としておこう．\n",
        "- そのままだと画像が小さくなり続けるのでpadding=2としてサイズ低下を防止する．\n",
        " - 入力（1x28x28）→Conv（32x28x28）→Pool（32x14x14）→Conv（64x14x14）→Pool（64x7x7）→Conv（128x7x7）→GAP→出力層（10次元） \n",
        " - GAPはGlobal Average Poolingで，チャネルごとにAverage Poolingを行う．\n",
        "   - これにより，入力画像サイズに依存しないモデルが実装可能となる．\n",
        "\n",
        "\n",
        "- nn.Conv2DはAPIリファレンス https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html によると\n",
        "``` python\n",
        "Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, \n",
        "       padding_mode='zeros', device=None, dtype=None)\n",
        "```\n",
        " - in_channels, out_channels, kernel_sizeだけ指定しておけば最低限問題なし．\n",
        "\n",
        "\n",
        "- nn.AvgPool2dはAPIリファレンス https://pytorch.org/docs/stable/generated/torch.nn.AvgPool2d.html によると\n",
        "```python\n",
        "AvgPool2d(kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True, divisor_override=None)\n",
        "```\n",
        " - kernel_size，strideを指定するのが一般的である．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gXIvODjA4NLc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# 非常にシンプルな4層のCNN（Encoder3層＋出力層）を設計する．\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, in_channels, output_dim):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.output_dim = output_dim\n",
        "        # nn.Sequential()に積層していく\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, 32, 5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.AvgPool2d(2, 2),\n",
        "            nn.Conv2d(32, 64, 5, padding=2),\n",
        "            nn.ReLU(),\n",
        "            nn.AvgPool2d(2, 2),\n",
        "            nn.Conv2d(64, 128, 5, padding=2),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(128, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = F.adaptive_avg_pool2d(x, (1, 1))  #  サイズが（1x1）になるようにAvgPoolingする\n",
        "        x = x.view(-1, 128)\n",
        "        return self.classifier(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "whnzT58A4NLd"
      },
      "outputs": [],
      "source": [
        "print(device)\n",
        "# 関数等は使い回すが，各インスタンスは再生成する必要がある．\n",
        "cnn = SimpleCNN(1, 10)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "lr = 0.001\n",
        "opt = torch.optim.Adam(cnn.parameters(), lr=lr) # cnnのパラメータを入れる．\n",
        "\n",
        "hist_cnn = []\n",
        "n_epochs = 20  # 20 epochs訓練する\n",
        "\n",
        "cnn = cnn.to(device)  # GPUで訓練できるようにする．\n",
        "cnn.train()  # netを訓練モードにする．\n",
        "\n",
        "for epoch in trange(n_epochs, desc=\"epoch\"):  # 訓練\n",
        "    loss, train_acc = train(cnn, opt, criterion, dl_train, device)\n",
        "    test_acc, _ = evaluate(cnn, dl_test, device)\n",
        "    hist_cnn.append([loss, train_acc, test_acc])\n",
        "\n",
        "print(hist_cnn[-1])\n",
        "plot_history(np.array(hist_cnn))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHHyxv7I4NLd"
      },
      "outputs": [],
      "source": [
        "# 出力を試しに確認してみる．\n",
        "for x,y in dl_test: # 1イテレーション分のデータを取得\n",
        "    break\n",
        "net = net.to(\"cpu\")\n",
        "out = net(x)\n",
        "print(\"Xの書式\", x.shape)\n",
        "print(\"Shapeの確認\", out.shape)\n",
        "print(\"1データ目の出力\", out[0])\n",
        "transforms.functional.to_pil_image(x[0].view(28, 28))  # 画像の確認"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYJqbJaQ4NLd"
      },
      "source": [
        "## 同じ要領でVGGを作ってみよう．\n",
        "- 上述したSimpleCNNをコピペし，VGGライクなネットワークを構築して訓練してみよう．\n",
        "- 訓練部分や可視化部分もコピペで良い．\n",
        "- 詳細なパラメータは原著論文を参照されたい．\n",
        "  - https://arxiv.org/abs/1409.1556\n",
        "- ただし，今回画像サイズが28x28の都合もあり，Pooingをstride=2で実施すると精々4回が限度である．\n",
        "  - そこで3Block程度の小さなVGGを作ることにしよう．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irP3qf_64NLe"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# 書くのが面倒になるのでnn.Moduleにまとめておく．\n",
        "class CR(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(CR, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, stride=1, padding=1),  # 画像サイズを落とさないようにpadding\n",
        "            nn.ReLU()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "\n",
        "# VGG16をベースに，Pooling時のStrideを変更したVer\n",
        "class smallVGG(nn.Module):\n",
        "    def __init__(self, in_channels, output_dim):\n",
        "        super(smallVGG, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.output_dim = output_dim\n",
        "        # nn.Sequential()に積層していく\n",
        "        self.encoder = nn.Sequential(\n",
        "            CR(in_channels, 16),  # フィルタも減らしておく\n",
        "            CR(16, 16),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            CR(16, 32),\n",
        "            CR(32, 32),\n",
        "            nn.MaxPool2d(2, 2),\n",
        "            CR(32, 64),\n",
        "            CR(64, 64),\n",
        "            CR(64, 64),\n",
        "            nn.MaxPool2d(2, 2)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(64, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = F.adaptive_avg_pool2d(x, (1, 1))  #  サイズが（1x1）になるようにAvgPoolingする\n",
        "        x = x.view(-1, 64)\n",
        "        return self.classifier(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5nJ1PSd4NLe"
      },
      "outputs": [],
      "source": [
        "print(device)\n",
        "# 関数等は使い回すが，各インスタンスは再生成する必要がある．\n",
        "cnn = smallVGG(1, 10)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "lr = 0.001\n",
        "opt = torch.optim.Adam(cnn.parameters(), lr=lr) # cnnのパラメータを入れる．\n",
        "\n",
        "hist_cnn = []\n",
        "n_epochs = 20  # 20 epochs訓練する\n",
        "\n",
        "cnn = cnn.to(device)  # GPUで訓練できるようにする．\n",
        "cnn.train()  # netを訓練モードにする．\n",
        "\n",
        "for epoch in trange(n_epochs, desc=\"epoch\"):  # 訓練\n",
        "    loss, train_acc = train(cnn, opt, criterion, dl_train, device)\n",
        "    test_acc, _ = evaluate(cnn, dl_test, device)\n",
        "    hist_cnn.append([loss, train_acc, test_acc])\n",
        "\n",
        "print(hist_cnn[-1])\n",
        "plot_history(np.array(hist_cnn))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7zS06gl4NLe"
      },
      "source": [
        "## ResNetライクなモデルも作ってみよう\n",
        "- ResNetを通じて，BatchNormalizationとSkipConnectionという重要な概念の利用方法を学ぼう．\n",
        "- 詳細なパラメータは原著論文を参照されたい．\n",
        "  - https://arxiv.org/abs/1512.03385\n",
        "\n",
        "### 練習問題\n",
        "- 上のVGGライクモデルを改良してResNetライクに変更してみよう．\n",
        "- 今回の改良ポイントはconvreluにBatchNormを挿入して，conv-bn-reluにすることと，\n",
        "- 各Blockの前後にショートカットゲートを挿入することに挑戦しよう．\n",
        "- 少し難しいと思うので，1度自分で考えてみる→ググって調べてみる→動画で解説を見ると進めていこう．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kuSY6vB4NLe"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# 書くのが面倒になるのでnn.Moduleにまとめておく．\n",
        "class CBR(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(CBR, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, stride=1, padding=1),  # 画像サイズを落とさないようにpadding\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, rep=2) -> None:\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.rep = rep\n",
        "        layers = []\n",
        "        inch = in_channels\n",
        "        for i in range(rep):\n",
        "            layers.append(CBR(inch, out_channels))\n",
        "            inch = out_channels\n",
        "        self.block = nn.Sequential(*layers)\n",
        "        self.pwconv = nn.Conv2d(in_channels, out_channels, 1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.block(x)\n",
        "        out = self.pwconv(x) + out\n",
        "        return self.pool(out)\n",
        "\n",
        "\n",
        "# VGG16をベースに，Pooling時のStrideを変更したVer\n",
        "class smallResNet(nn.Module):\n",
        "    def __init__(self, in_channels, output_dim):\n",
        "        super(smallResNet, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.output_dim = output_dim\n",
        "        # nn.Sequential()に積層していく\n",
        "        self.encoder = nn.Sequential(\n",
        "           BasicBlock(in_channels, 16, rep = 2),\n",
        "           BasicBlock(16, 32, rep = 2),\n",
        "           BasicBlock(32, 64, rep = 3)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(64, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = F.adaptive_avg_pool2d(x, (1, 1))  #  サイズが（1x1）になるようにAvgPoolingする\n",
        "        x = x.view(-1, 64)\n",
        "        return self.classifier(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J2drCRY34NLe"
      },
      "outputs": [],
      "source": [
        "from tqdm.notebook import trange\n",
        "\n",
        "print(device)\n",
        "# 関数等は使い回すが，各インスタンスは再生成する必要がある．\n",
        "cnn = smallResNet(1, 10)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "lr = 0.001\n",
        "opt = torch.optim.Adam(cnn.parameters(), lr=lr) # cnnのパラメータを入れる．\n",
        "\n",
        "hist_cnn = []\n",
        "n_epochs = 20  # 20 epochs訓練する\n",
        "\n",
        "cnn = cnn.to(device)  # GPUで訓練できるようにする．\n",
        "cnn.train()  # netを訓練モードにする．\n",
        "\n",
        "for epoch in trange(n_epochs, desc=\"epoch\"):  # 訓練\n",
        "    loss, train_acc = train(cnn, opt, criterion, dl_train, device)\n",
        "    test_acc, _ = evaluate(cnn, dl_test, device)\n",
        "    hist_cnn.append([loss, train_acc, test_acc])\n",
        "\n",
        "print(hist_cnn[-1])\n",
        "plot_history(np.array(hist_cnn))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NNVfCoRC4NLf"
      },
      "source": [
        "## SE Netライクなモデルを実装してみよう\n",
        "- SE Netの実装を通じて，BatchNormalizationとSkipConnectionという重要な概念の利用方法を学ぼう．\n",
        "- 詳細なパラメータは原著論文を参照されたい．\n",
        "  - https://arxiv.org/abs/1709.01507\n",
        "\n",
        "### 練習問題\n",
        "- 上のResNetライクモデルを改良してSE-blockを挿入してみよう．\n",
        "- 今回の改良ポイントはSE-Block(論文中のFig1)を各モジュールの末尾に挿入することである．\n",
        "- 少し難しいと思うので，1度自分で考えてみる→ググって調べてみる→動画で解説を見ると進めよう．"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVz1GqcY4NLf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# 書くのが面倒になるのでnn.Moduleにまとめておく．\n",
        "class CBRSE(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(CBRSE, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, 3, stride=1, padding=1),  # 画像サイズを落とさないようにpadding\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(),\n",
        "            SE(out_channels, r=8)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "\n",
        "class SE(nn.Module):\n",
        "    def __init__(self, in_channels, r = 8):\n",
        "        super(SE, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.r = r\n",
        "        self.c1 = nn.Conv2d(in_channels, in_channels//r, 1)\n",
        "        self.c2 = nn.Conv2d(in_channels//r, in_channels, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.adaptive_avg_pool2d(x, (1, 1))  #  サイズが（1x1）になるようにAvgPoolingする\n",
        "        out = F.relu(self.c1(out))\n",
        "        out = F.sigmoid(self.c2(out))\n",
        "        return x * out\n",
        "\n",
        "\n",
        "class SEBasicBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, rep=2) -> None:\n",
        "        super(SEBasicBlock, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.rep = rep\n",
        "        layers = []\n",
        "        inch = in_channels\n",
        "        for i in range(rep):\n",
        "            layers.append(CBRSE(inch, out_channels))\n",
        "            inch = out_channels\n",
        "        self.block = nn.Sequential(*layers)\n",
        "        self.pwconv = nn.Conv2d(in_channels, out_channels, 1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.block(x)\n",
        "        out = self.pwconv(x) + out\n",
        "        return self.pool(out)\n",
        "\n",
        "\n",
        "# VGG16をベースに，Pooling時のStrideを変更したVer\n",
        "class smallSEResNet(nn.Module):\n",
        "    def __init__(self, in_channels, output_dim):\n",
        "        super(smallSEResNet, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.output_dim = output_dim\n",
        "        # nn.Sequential()に積層していく\n",
        "        self.encoder = nn.Sequential(\n",
        "           SEBasicBlock(in_channels, 16, rep = 2),\n",
        "           SEBasicBlock(16, 32, rep = 2),\n",
        "           SEBasicBlock(32, 64, rep = 3)\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(64, output_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        x = F.adaptive_avg_pool2d(x, (1, 1))  #  サイズが（1x1）になるようにAvgPoolingする\n",
        "        x = x.view(-1, 64)\n",
        "        return self.classifier(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUgjpJuD4NLf"
      },
      "outputs": [],
      "source": [
        "print(device)\n",
        "# 関数等は使い回すが，各インスタンスは再生成する必要がある．\n",
        "cnn = smallSEResNet(1, 10)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "lr = 0.001\n",
        "opt = torch.optim.Adam(cnn.parameters(), lr=lr) # cnnのパラメータを入れる．\n",
        "\n",
        "hist_cnn = []\n",
        "n_epochs = 20  # 20 epochs訓練する\n",
        "\n",
        "cnn = cnn.to(device)  # GPUで訓練できるようにする．\n",
        "cnn.train()  # netを訓練モードにする．\n",
        "\n",
        "for epoch in trange(n_epochs, desc=\"epoch\"):  # 訓練\n",
        "    loss, train_acc = train(cnn, opt, criterion, dl_train, device)\n",
        "    test_acc, _ = evaluate(cnn, dl_test, device)\n",
        "    hist_cnn.append([loss, train_acc, test_acc])\n",
        "\n",
        "print(hist_cnn[-1])\n",
        "plot_history(np.array(hist_cnn))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}